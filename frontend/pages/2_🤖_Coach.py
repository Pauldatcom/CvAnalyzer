import streamlit as st
from mistralai import Mistral
import os
from dotenv import load_dotenv
import urllib.parse

# Chargement des variables d'environnement
load_dotenv()
api_key = os.getenv("MISTRAL_API_KEY")
model = "mistral-large-latest"
client = Mistral(api_key=api_key)

st.set_page_config(page_title="Assistant RH IA", layout="wide")
st.title("ü§ñ Assistant RH contextuel & Offres personnalis√©es")




# =============================================================================
# 1) Docstring en t√™te :
#    """
#    Page 2 ‚Äì Coach RH contextuel :
#    - Charge le contexte complet depuis st.session_state : 
#         cv_original, cv_modifi√©, fiche_de_poste, analyse_LLaMA.
#    - Initialise l‚Äôhistorique du chat (st.session_state["chat_history"]).
#    - √Ä chaque message utilisateur, envoie le contexte + chat_history √† Mistral.
#    - Affiche la r√©ponse IA et met √† jour st.session_state["chat_history"].
#    - En bas, propose des liens vers des offres similaires.
#    """
# =============================================================================

# =============================================================================
# 2) Chargement du contexte :
#    - if "cv_modified" in st.session_state: afficher le texte du CV modifi√©.
#    - Sinon, demander √† l‚Äôutilisateur de revenir sur la page 1 pour g√©n√©rer le CV.
# =============================================================================

# =============================================================================
# 3) Zone de chat :
#    - st.chat_input() pour le message utilisateur.
#    - Quand l‚Äôutilisateur envoie un message :
#       ‚Ä¢ Construire le prompt Mistral : system + contexte (CV orig., CV mod., offre, analyse).
#       ‚Ä¢ Appeler mistralai.chat(messages=‚Ä¶, temperature=‚Ä¶).
#       ‚Ä¢ Afficher la r√©ponse IA avec st.chat_message(role="assistant", ‚Ä¶).
#       ‚Ä¢ Conserver l‚Äôhistorique dans st.session_state["chat_history"].
# =============================================================================

# =============================================================================
# 4) Suggestions de liens d‚Äôoffres externes :
#    - √Ä partir du titre du poste, g√©n√©rer un lien Google/Indeed/LinkedIn vers des offres similaires.
#    - Ex. :
#         st.markdown(f"[Voir d‚Äôautres offres {job_title} sur LinkedIn](https://www.linkedin.com/jobs/search?keywords={job_title})")
# =============================================================================

# ------------------ Injection du CSS (sans bloc vide) ------------------
if os.path.exists("frontend/style.css"):
    with open("frontend/style.css", "r") as f:
        css_content = f.read()
    # Injecte le CSS complet sur une seule ligne pour √©viter un bloc Markdown vide
    st.markdown(f"<style>{css_content}</style>", unsafe_allow_html=True)
    # Cache le conteneur que Streamlit pourrait cr√©er autour de ce <style>
    st.markdown(
        "<style>[data-testid='stElementContainer']:has(style) {display: none !important;}</style>",
        unsafe_allow_html=True,
    )

# ------------------ CONTEXTE POUR LE CHAT ------------------

cv = st.session_state.get("cv_text", "")
cv_updated = st.session_state.get("updated_cv_text", "")
offer = st.session_state.get("offer_text", "")
llama_analysis = st.session_state.get("llama_analysis", "")

system_msg = f"""
Tu es un recruteur expert. Voici le contexte :
- CV original : {cv[:1000]}
- CV modifi√© par l'IA : {cv_updated[:1000]}
- Fiche de poste : {offer[:1000]}
- Analyse LLaMA 3 : {llama_analysis[:1500]}

R√©ponds comme un recruteur : explique, conseille, reformule, anticipe les questions d'entretien.
"""

# ------------------ AFFICHAGE DU CV MODIFI√â ------------------

if cv_updated:
    st.subheader("‚úèÔ∏è CV mis √† jour par l'IA")
    st.text_area("CV r√©√©crit", cv_updated, height=300)

# ------------------ CHATBOT RH ------------------

st.subheader("üí¨ Discuter avec l'IA RH")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = [{"role": "system", "content": system_msg}]

for msg in st.session_state.chat_history[1:]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if prompt := st.chat_input("Posez votre question √† l'assistant RH..."):
    st.chat_message("user").markdown(prompt)
    st.session_state.chat_history.append({"role": "user", "content": prompt})

    try:
        response = client.chat.complete(model=model, messages=st.session_state.chat_history)
        reply = response.choices[0].message.content
    except Exception as e:
        reply = f"Erreur API : {e}"

    st.chat_message("assistant").markdown(reply)
    st.session_state.chat_history.append({"role": "assistant", "content": reply})


# ------------------ RECHERCHE D'OFFRES BAS√âE SUR LA FICHE DE POSTE ------------------

st.divider()

with st.expander("üîç Voir les offres recommand√©es"):
    if offer:
        titre_poste = st.session_state.get("offer_title", "data")
        query = urllib.parse.quote_plus(titre_poste.strip())

        st.markdown(
            f"üîó [Voir toutes les offres]"
            f"(https://www.welcometothejungle.com/fr/jobs?query={query})"
        )

        st.markdown("### üéØ Offres recommand√©es :")
        st.markdown(f"- [üîó Welcome to the Jungle](https://www.welcometothejungle.com/fr/jobs?query={query})")
        st.markdown(f"- [üîó LinkedIn Jobs](https://www.linkedin.com/jobs/search/?keywords={query})")
        st.markdown(f"- [üîó Indeed France](https://fr.indeed.com/jobs?q={query})")
        st.markdown(
            f"- [üîó Glassdoor]"
            f"(https://www.glassdoor.fr/Emploi/{query}-emplois-SRCH_KO0,{len(query)}.htm)"
        )
        st.markdown(f"- [üîó Jooble](https://fr.jooble.org/SearchResult?ukw={query})")
    else:
        st.warning("Veuillez analyser une fiche de poste dans la page pr√©c√©dente pour voir les offres recommand√©es.")
